
# ğŸ§  AIBackend-Lab â€” AI-Augmented Backend Playground

AIBackend-Lab is a modular backend system built to explore the integration of modern LLMs into real-world backend architectures using FastAPI, PostgreSQL, Redis, Ollama, and ChromaDB.  
Developed as part of a 30-day roadmap to become an AI-integrated backend engineer in 2025.

---

## ğŸš€ Features Implemented (Days 1â€“8)

### âœ… Core Backend
- ğŸ”§ **FastAPI + PostgreSQL + Docker**: Production-ready async backend setup
- ğŸ” **JWT Auth + Role-Based Access Control (RBAC)**: Secure user access system

### ğŸ¤– LLM-Driven Tools
- ğŸ§  **Password Strength Advisor**: Uses local Mistral model via Ollama to provide password feedback
- âš™ï¸ **Function Calling**: LLM decides which registered backend function to invoke using JSON schema
- ğŸ§¾ **Log Summarization**: Converts raw log data into human-readable summaries using local LLM

### ğŸ” RAG + Semantic Search
- ğŸ§  **ChromaDB Integration**: Stores log embeddings using `sentence-transformers`
- ğŸ’¬ **RAG-Based Chat with Logs**: Conversational API over logs with retrieval-augmented generation

### ğŸŒ Real-Time LLM Streaming
- ğŸŒŠ **WebSocket API**: Streams live LLM-generated responses using Ollama (Mistral model)

---

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI, Python 3.10+
- **Auth**: JWT, OAuth2, Pydantic
- **LLMs**: Mistral via Ollama (local), Sentence-Transformers
- **Vector Store**: ChromaDB
- **Database**: PostgreSQL
- **Realtime**: FastAPI WebSockets
- **Cache/Broker**: Redis (future integration)
- **DevOps**: Docker, Docker Compose

---

## ğŸ“ Project Structure

```

aibackend-lab/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # Route handlers
â”‚   â”œâ”€â”€ core/             # Configs, auth setup
â”‚   â”œâ”€â”€ services/         # Business logic & AI tools
â”‚   â”œâ”€â”€ schemas/          # Pydantic models
â”‚   â””â”€â”€ utils/            # Embedding, streaming, helpers
â”œâ”€â”€ scripts/              # Data setup & helper scripts
â”œâ”€â”€ requirements/         # requirements.txt + env files
â”œâ”€â”€ docker/               # Docker configurations
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

````

---

## ğŸ§ª Running Locally

### âš™ï¸ Prerequisites
- Python 3.10+
- Docker + Docker Compose
- [Ollama installed](https://ollama.com/) locally with a model like `mistral`

### ğŸš€ Start the App

```bash
# 1. Clone the repository
git clone https://github.com/JukaleManmath/aibackend-lab.git
cd aibackend-lab

# 2. Start Docker services
docker-compose up --build

# 3. Run Ollama in another terminal
ollama run mistral

# 4. Access the app
http://localhost:8000/docs
````

---

## ğŸ“¸ Key Endpoints

| Endpoint                  | Description                               |
| ------------------------- | ----------------------------------------- |
| `POST /auth/login`        | JWT login                                 |
| `POST /password-feedback` | Get feedback from LLM for a password      |
| `POST /summarize-logs`    | Send logs and receive summarized insights |
| `POST /chat/logs`         | Chat with logs via RAG                    |
| `GET /ws/chat`            | WebSocket stream for real-time LLM chat   |

---

## ğŸ”„ In Progress (Upcoming Days)

* Resume Ranker using Embeddings (Day 9)
* Whisper-powered Voice Transcription (Day 11)
* Multi-Agent Task Planner (Day 16)
* PDF Upload + Q\&A via LLM (Day 19)

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¨â€ğŸ’» Author

**Manmath Jukale**
[Portfolio](https://manmath-jukale-portfolio.vercel.app) | [GitHub](https://github.com/JukaleManmath) | [LinkedIn](https://linkedin.com/in/jukalemanmath)




